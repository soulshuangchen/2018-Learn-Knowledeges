方差是度量一个数据分类程度的统计量，它是每个样本值与全体样本值的平均数之差的平方值的平均数

期望是试验中每次可能结果的概率乘以其结果的总和  越离散越好？


主成分分析PCA主方向就是样本投影后方差最大的那个方向，次方向是方差垂直于主方向的所有方向中能够使得方差再大的那个方向


喂给模型的时候是把原始数据中的数字给与




SVM:支持向量机SVM
SVM 可以应用于线性分类和非线性分类问题，取决于核函数的选取
SVM 是凸问题，深度学习都是非凸问题
SVM 是一种优化的分类算法，其动机是寻找一个最佳的决策边界，使得从决策边界与各组数据之间存在 margin ，并且需要使各侧的 margin 最大化。
margin值即为所有点到边界的垂直距离的最小值


卷积操作（图像）：输入图像：n*n大小，卷积核大小：f*f，步长为s，填充为p，感受野为rin，特征点之间跳跃为jin，左上角特征的感受野中心为cout。

输出图像大小为m，感受野为rout，特征点之间跳跃为jout，左上角特征的感受野中心cout

m=|（n+2p-f）/s|+1  可能是绝对值，也可能是方括号
jout=jin*s
rout=rin+（f-1）*jin
cout=cin+（（f-1）/2-p）*jin


100×100×n，3×3 卷积核，输出是 50×50×10，算进行了多少次乘-加操作？

输出的每个像素点都要经过 3×3×n = 27 次乘-加操作，因此总共需要进行 50×50×10×27 次乘-加操作。


异常检测算法(高斯分布算法)，可以适用于异常(也就是负样本)比较少的情况。

物体检测：YOLO、R-CNN、Fast R-CNN、Faster R-CNN、Mask R-CNN、SSD 等；
YOLO 算法直接利用一个卷积神经网络就输出物体所在的位置以及所属的类别，是一个端到端的系统，因此检测速度特别快，可以达到实时性的要求。


凸多边形：遍历所有相邻顶点，以两点坐标求得直线方程，判断其余顶点是否在直线同侧
相邻点：对x进行排序呢（同一x下，有大于两个的不同y值的点，那么一定是凹多边形）



随机梯度下降法：适用于样本量大的情况，需要内存小；但每一步可能并不是向着最优解方向 ；
牛顿法：收敛速度快；但对目标函数有严格要求，必须有连续的一、二阶偏导数，计算量大。



正则化方法：
数据增强(Data Augmentation)、L1 正则化、L2 正则化、 Dropout、Drop Connect 和早停(Early stop)。

正则化：

L0 范数：向量中非0元素的个数。
L1 范数 (Lasso Regularization)：向量中各个元素绝对值的和。
L2 范数(Ridge Regression)：向量中各元素平方和再求平方根。
L0 范数和 L1 范数都能够达到使参数稀疏的目的，但 L0 范数更难优化求解，L1 范数是 L0 范数的最优凸近似，而且它比 L0 范数要容易优化求解。
L2 范数不但可以防止过拟合，提高模型的泛化能力，还可以让我们的优化求解变得稳定和快速。L2 范数对大数和 outlier 更敏感！